[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ADRF Onboarding Handbook",
    "section": "",
    "text": "Preface\nThis is a revised version of the Coleridge Initiative ADRF User On-boarding Handbook\nThis is a living document intended to show new ADRF users how to use the platform for common tasks"
  },
  {
    "objectID": "access.html#requesting-an-account",
    "href": "access.html#requesting-an-account",
    "title": "1  Obtaining ADRF Access and Account Set Up",
    "section": "Requesting an Account",
    "text": "Requesting an Account\n\nAgency-affiliated researcher. If you are an agency-affiliated researcher, your agency will set up an ADRF account for you.\nIndividual part of a training program. If you are part of a training program, Coleridge Initiative will create an account for you once you have been accepted into the program."
  },
  {
    "objectID": "access.html#account-registration-and-onboarding-tasks",
    "href": "access.html#account-registration-and-onboarding-tasks",
    "title": "1  Obtaining ADRF Access and Account Set Up",
    "section": "Account Registration and Onboarding Tasks",
    "text": "Account Registration and Onboarding Tasks\n\nYou will receive an email invitation to activate your account. The email will come from http://okta.com, so please make sure that it doesn’t get caught in your email spam filter. Follow the steps outlined in the email to set up your password and your multi-factor authentication preferences. Clink on the link below to watch a video walking through the steps.\nAfter activating your account, you will be logged in to the ADRF Applications page. Proceed to the Data Stewardship application by clicking on the icon.\nIn the Data Stewardship application, you will notice a “Tasks” section with a number of items you will need to complete before you can gain access to the project space. Refer to the next section for details about the onboarding process."
  },
  {
    "objectID": "access.html#obtaining-adrf-access",
    "href": "access.html#obtaining-adrf-access",
    "title": "1  Obtaining ADRF Access and Account Set Up",
    "section": "Obtaining ADRF Access",
    "text": "Obtaining ADRF Access\n\nAgency-affiliated researcher. If you are an agency-affiliated researcher using an agency-sponsored account, you will be granted ADRF access once you complete your onboarding tasks and required data access agreements. If you are an self-paying agency-affiliated researcher, your ADRF access is conditional on receipt of payment. If your institution of Office of Sponsored Programs will be submitting payment on your behalf, please be aware of potential access delays. Whenever possible, the Coleridge Initiative advises paying with a personal credit card or institutional payment card and using the generated invoice to request reimbursement.\nIndividual part of a training program. If you are part of a training program, you will be granted ADRF access once you complete your onboarding tasks and required data access agreements."
  },
  {
    "objectID": "access.html#more-information",
    "href": "access.html#more-information",
    "title": "1  Obtaining ADRF Access and Account Set Up",
    "section": "More Information",
    "text": "More Information\nIf you have any questions, please contact support@coleridgeinitiative.org."
  },
  {
    "objectID": "onboarding.html#data-stewardship-app",
    "href": "onboarding.html#data-stewardship-app",
    "title": "2  Onboarding Modules and Security Training",
    "section": "Data Stewardship App",
    "text": "Data Stewardship App\nThee Data Stewardship web-based application is positioned primarily as the management and monitoring console for project and data stewards. It provides detailed insight on project configurations, user activity, user onboarding status, and overall cost of a project on the ADRF. We focus on four primary pillars of information a Project/Data Steward most often focuses on:\n\nPeople – Who are the members of projects, how often do they use the ADRF, what exports have they requested and their status, estimated cost per person/project for current month and for the project since inception, and detailed usage metrics.\nProjects – Details of project start/end dates, abstract description, number of members onboarded and pending, and resources the project has access to (i.e. datasets, etc).\nDatasets – Description of the dataset, location on the ADRF (database or file system), size, name of the data steward(s), and the link to Enterprise Data Catalog (Informatica) describing the dataset and metadata.\nAgreements – What agreements are related to these projects, indication of each member’s signing status, members pending signature, and term (dates) covered by the agreement(s).\n\nAs mentioned, the data stewardship application will track your ADRF usage. The app will also consolidate your ADRF Terms of Use, Security Training Quiz, and Security Training Video into one place. In order to complete ADRF onboarding, all three of the mentioned tasks are to be completed by the user (researcher). To access the Data Stewardship app, log in using your credentials at https://adrf.okta.com and click on the Data Stewardship icon. See picture below:\n\n\n\n\n\nOnce inside the Data Stewardship app, you have access to your personal workspace sessions statistics and the three tasks. See the example below:"
  },
  {
    "objectID": "onboarding.html#adrf---terms-of-use",
    "href": "onboarding.html#adrf---terms-of-use",
    "title": "2  Onboarding Modules and Security Training",
    "section": "ADRF - Terms of Use",
    "text": "ADRF - Terms of Use\nThe Terms of Use need to be completed before you are given access to the data and project sace inside the ADRF. To complete ADRF Terms of Use, open the Data Stewardship app and click on ADRF - Terms of Use. This will direct you to an Docusign site to complete the signing of the agreement."
  },
  {
    "objectID": "onboarding.html#security-training-video",
    "href": "onboarding.html#security-training-video",
    "title": "2  Onboarding Modules and Security Training",
    "section": "Security Training Video",
    "text": "Security Training Video\nThe Security Training Video needs to be completed as well. To complete the training, open the Data Stewardship app and click on Security Training Video. This will direct you to the video; click Mark Complete when you have completed this training."
  },
  {
    "objectID": "onboarding.html#security-training-quiz",
    "href": "onboarding.html#security-training-quiz",
    "title": "2  Onboarding Modules and Security Training",
    "section": "Security Training Quiz",
    "text": "Security Training Quiz\nThe Security Training Quiz needs to be completed after the Security Training Video. To complete the train- ing, open the Data Stewardship app and click on Security Training Quiz. This will direct you to the quiz, where you must answer five out of six questions correctly to pass."
  },
  {
    "objectID": "dosanddonts.html#exact-numbers",
    "href": "dosanddonts.html#exact-numbers",
    "title": "3  Do’s and Don’ts For Discussing Data Inside the ADRF",
    "section": "Exact Numbers",
    "text": "Exact Numbers\nDo not describe a statistic in exact numbers. If you would like to communicate these values while not in person, you can have a private discussion via the projects drive inside the ADRF.\nExample: If an average within a specific group was 5,000, you would need to convey this average on the projects drive."
  },
  {
    "objectID": "dosanddonts.html#comparing-values",
    "href": "dosanddonts.html#comparing-values",
    "title": "3  Do’s and Don’ts For Discussing Data Inside the ADRF",
    "section": "Comparing Values",
    "text": "Comparing Values\nWhen comparing values, you are permitted to say that one value is more than, less than, or about the same as another. However, you cannot refer to the exact difference between the two numbers.\nIn practice, you can use pluses and minuses to convey differences between values for data that has not been exported from the ADRF.\nExample: “The mean for Group A was roughly the same as the mean for Group B, but these values were both greater than that of Group C.”"
  },
  {
    "objectID": "dosanddonts.html#percentagesproportions",
    "href": "dosanddonts.html#percentagesproportions",
    "title": "3  Do’s and Don’ts For Discussing Data Inside the ADRF",
    "section": "Percentages/Proportions",
    "text": "Percentages/Proportions\nPercentages and proportions also cannot be directly mentioned. Instead, you can refer to the percentage/proportion within 25%.\nExample: If a proportion was 30%, you could say “The proportion is about 25%” or “The proportion is between 25% and 50%.”"
  },
  {
    "objectID": "accessing.html#locate-your-data-in-a-database",
    "href": "accessing.html#locate-your-data-in-a-database",
    "title": "4  Accessing Your Data",
    "section": "Locate your Data in a Database",
    "text": "Locate your Data in a Database\n\nThe ADRF stores data using Redshift. The simplest way to locate and get a quick overview of your data in a database is to use DBeaver. Please see the section on Data Organization, Amazon RedShift Querying Guide to locate and connect to your data.\n\nG: Drive\nUnstructured data is located on the G: drive inside the file system.\n\n\n\n\n\n\n\nExternal Data and Code\nPlease note that importing of external data and code is restricted to only Coleridge staff. Given the secure and protected environment provided by the ADRF, all code, data, and packages that are coming from outside of the ADRF must be carefully vetted to prevent leaks, disclosure, or unauthorized access. This means that there is no direct method for uploading data or code from your system to the ADRF. Please contact support@coleridgeinitiative.org for any questions or assistance on importing your own code, data, or packages."
  },
  {
    "objectID": "storing.html#eligible-locations",
    "href": "storing.html#eligible-locations",
    "title": "5  Storing Analytic Results",
    "section": "Eligible Locations",
    "text": "Eligible Locations\n\nUser Drive\nThe U: drive is your user drive; it’s where you will store any files you are working on. Only the user will have access to the U: drive. For example, if user A wants to share information with user B who is on the same project, user A will need to save files to a P: drive folder and not folders in their U: drive since user B will not be able to access user A’s U: drive.\n\n\nProject Drive\nThe P: drive also allows permanent storage. This drive is accessible by anyone on the same project, but not across projects. This is the only drive outside of the user drive where saved files will not be erased after logging out of the ADRF.\n\n\nSQL\nEach project will have a project-specific database created. All members of the project will have read and write permissions for data and may also create their own objects (tables, etc.). The project databases are prefixed with pr-."
  },
  {
    "objectID": "storing.html#ineligible-locations",
    "href": "storing.html#ineligible-locations",
    "title": "5  Storing Analytic Results",
    "section": "Ineligible Locations",
    "text": "Ineligible Locations\nThe G: drive (data), the L: drive (Libs), and the desktop are not eligible for long-term file storing. You won’t have permissions to write to either the G: drive or the L: drive. The desktop will function only as temporary storage—as soon as a user is logged out of the ADRF, your desktop will be cleared. Additionally, since Wi-Fi connectivity can be imperfect, desktop storage for any amount of time is not recommended."
  },
  {
    "objectID": "storing.html#storage-size-restrictions",
    "href": "storing.html#storage-size-restrictions",
    "title": "5  Storing Analytic Results",
    "section": "Storage Size Restrictions",
    "text": "Storage Size Restrictions\nStorage size varies by project, but is capped at a predetermined amount. Additional storage costs may vary depending on the resource requirements. https://aws.amazon.com/appstream2/pricing/"
  },
  {
    "objectID": "storing.html#best-practices",
    "href": "storing.html#best-practices",
    "title": "5  Storing Analytic Results",
    "section": "Best Practices",
    "text": "Best Practices\nTo save storage space, try not to save raw data tables—in particular, don’t save copies of or large subsets of data that are already available through standard sources. Instead, access data through the methods described in the prior sections here, as appropriate for your programming language or program.\nOrganize folders in a way that makes sense for your particular project. For example, you might have folders for a particular analysis or sub-projects. Dates on file names can be helpful for version control.\nKeep tabs on how much storage you are using compared to the allocated amount of storage."
  },
  {
    "objectID": "sharing.html#adrf-messenger",
    "href": "sharing.html#adrf-messenger",
    "title": "6  Sharing Information within the ADRF",
    "section": "ADRF Messenger",
    "text": "ADRF Messenger\nThe ADRF messenger is an internal collaboration tool and will be made available once testing is complete."
  },
  {
    "objectID": "sharing.html#shared-folders",
    "href": "sharing.html#shared-folders",
    "title": "6  Sharing Information within the ADRF",
    "section": "Shared Folders",
    "text": "Shared Folders\nShared folders within a project are a great way to share information with other members on a team project. Remember that when working with teams you may not share the ADRF screen (even project folders) with other members on video platforms or otherwise, whether or not your team members are working on the same project."
  },
  {
    "objectID": "sharing.html#sharing-restrictions",
    "href": "sharing.html#sharing-restrictions",
    "title": "6  Sharing Information within the ADRF",
    "section": "Sharing Restrictions",
    "text": "Sharing Restrictions\nAgain, remember that when working with teams you may not share the ADRF screen with other members on video platforms or otherwise, whether or not your team members are working on the same project.\nThe information contained in the ADRF is restricted to reside only in the ADRF for all purposes unless it passes Export Review. This means that it cannot be shared or potentially shared with any unauthorized parties. Do not write down any numbers or figures or tables corresponding to data in the ADRF. Copying and pasting is restricted, but manually circumventing this is also not permitted by your data agreements."
  },
  {
    "objectID": "export.html#export-review-guidelines",
    "href": "export.html#export-review-guidelines",
    "title": "7  Export guidelines",
    "section": "Export Review Guidelines",
    "text": "Export Review Guidelines\nTo provide ADRF users with the ability to draw from sensitive data, results that are exported from the ADRF must meet rigorous standards meant to protect privacy and confidentiality. To ensure that those standards are met, the ADRF Export Review team reviews each request to ensure that it follows formal guidelines that are set by the respective agency providing the data in partnership with the Coleridge Initiative. Prior to moving data into the ADRF from the agency, the Export Review team suggests default guidelines to implement, based on standard statistical approaches in the U.S. government 1, 2 as well as international standards 3, 4, and 5. The Data Steward from the agency supplying the data works with the team to amend these default rules in line with the agency’s requirements. If you are unsure about the review guidelines for the data you are using in the ADRF or if you have any questions relating to exports, please reach out to support@coleridgeinitiative.org before submitting an export request.\nTo learn more about limiting disclosure more generally, please refer to the textbook or view the videos.\n\nGeneral Best Practices for a Successful Export\n\nCurrently, the review process is highly manual: Reviewers will read your code and view your output files, which may be time-consuming.\nEach additional release adds disclosure risk and therefore limits subsequent releases; we ask that users limit the number of files they request to export to just the outputs necessary to produce a particular report or paper. If you are requesting an export of more than 10 files, there may be an additional charge.\nThe reviewers may ask you to make changes to your code or output to meet the requirements of guidelines that have been given by the providers of the data in the ADRF. Thus, we strongly encourage you to produce all output files—tables with rounded numbers, graphs with titles, and so forth—through code, rather than manually.\nWe ask that you only request review of final versions of output files, rather than in-progress versions. Any file containing intermediate output will be rejected.\nEvery code file should have a header describing the contents of the file, including a summary of the data manipulation that takes place in the file (e.g., regression, table or figure creation, etc.).\nDocumenting code by using comments throughout is helpful for disclosure reviews. The better the documentation, the faster the turnaround of export requests. If data files are aggregated, please provide documentation on the level of aggregation and for where in the code the aggregation takes place.\nTo help reviewers, who may not have seen your code before, we ask that users create meaningful variable names. For instance, if you are calculating outflows, it is better to name the variable “outflows” than to name it “var1.”\n\n\n\nTimelines for Export Process\n\nColeridge reviewers have five business days to complete an export from the day you submit an export request. However, timelines may differ depending on your agency, so please refer to your specific agency’s guidelines.\nThe review process can be delayed if the reviewer needs additional information or if the reviewer needs you to make changes to your code or output to meet the ADRF nondisclosure requirements."
  },
  {
    "objectID": "export.html#preparing-data-for-export",
    "href": "export.html#preparing-data-for-export",
    "title": "7  Export guidelines",
    "section": "Preparing Data for Export",
    "text": "Preparing Data for Export\n\nTables\n\nCell Sizes\n\nEach agency has specific disclosure review guidelines, especially with respect to the minimum allowable cell sizes for tables. Refer to these guidelines when preparing export requests. If you are unsure of what guidelines are in place for the dataset with which you are working in the ADRF, please reach out to support@coleridgeinitiative.org.\nFor individual-level data, please report the number of observations from each cell. For individual-level data, the default rule is to suppress cells with fewer than 10 observations, unless otherwise directed by the guidelines of the agency that provided the data.\nIf your table includes row or column totals or is dependent on a preceding or subsequent table, reviewers will need to take into account complementary disclosure risks—that is, whether the tables’ totals, or the separate tables when read together, might disclose information about individuals in the data in a way that a single, simpler table would not. Reviewers will work with you by offering guidance on implementing any necessary complementary suppression techniques.\n\nWeighted Data\n\nIf weighted results are to be exported, you must report both weighted and unweighted counts.\n\nRatios\n\nIf ratios are reported, please report the number of valid cases for both the numerator and the denominator (e.g., number of men in state X and number of women in state X, in addition to the ratio of women in state X).\n\nPercentiles\n\nDo not report exact percentiles. Instead, for example, you may calculate a “fuzzy median,” by averaging the true 45th and 55th percentiles.\n\nPercentages\n\nFor any reported percentages or proportions, the underlying counts of individuals contributing to the numerators and denominators must be provided for each statistic in the desired export.\n\nMaxima and Minima\n\nSuppress maximum and minimum values in general.\nYou may replace an exact maximum or minimum with a top-coded value.\n\n\n\n\nGraphs\n\nGraphs are representations of tables. Thus, for each graph (which may have, e.g., a jpg, pdf, png, or tif extension), provide the source data of the underlying table of the graph following the guidelines for tables above.\nBecause graphs and other figures take the most time to review, the number of generated graphs should be as low as possible. Please consider the possibility that you could export the underlying table instead, and generate the graph in another package.\nIf a graph is produced from aggregated data or from tables that have been disclosure-proofed following the guidelines above (e.g., bar charts of magnitudes), provide the underlying tables.\nIf a graph is produced directly from unit-record data but aggregated in the visualization (e.g., frequency histograms), provide the underlying tables.\nIf a graph is produced directly from unit-record data and displays unit-record values (e.g., scatterplots, plots of residuals), the graph can be released only after you ensure that individuals cannot be re-identified and that values can only be estimated with a high level of uncertainty. Further processing to meet this requirement can include, but is not restricted to, cutting off the tails of a distribution, removing outliers, jittering the actual values, and removing or modifying axis values.\nIf a graph is produced from the results of modeling or derivation and uses the unit-record data (e.g., regression curves), the graph can be released only if the values cannot be used to find original data values.\n\nGraphs of this type are generally automatically cleared.\nFor precision/recall graphs, you will need to report the sample size used to generate your model(s).\n\n\n\n\nModel Output\n\nOutput from regression or machine-learning models generally does not pose a risk of disclosing personally identifiable information, as long as the models are not based on small samples. Provide the counts for each variable that produces the model output. If categorical variables are used then provide the counts for each category."
  },
  {
    "objectID": "export.html#submitting-an-export-request",
    "href": "export.html#submitting-an-export-request",
    "title": "7  Export guidelines",
    "section": "Submitting an Export Request",
    "text": "Submitting an Export Request\nTo request an export be reviewed, please watch the following video or follow the instructions below:\nExport Video\n\nClick here: http://adrf.okta.com (ADRF 3).\nInput your login credentials.\nVerify yourself with Okta (download Okta Verify on your smartphone or other device).\nChoose your project as seen in the photo below. For the purpose of this document, you are seeing the Coleridge Initiative Associate Access project.\n\n\n\n\n\n\n\nSelect Desktop and login with the same credentials you had done previously.\nUpon entering the ADRF, a chrome page will appear as shown in the photo below. On this page, click Export Request in the bottom left corner. Or, from the ADRF desktop, open Google Chrome and navigate to export.adrf.net. (Note: export.adrf.net is an address that will only work within the ADRF desktop).\n\n\n\n\n\n\n\nClick My Requests, or the top (person-shaped) icon, at the left side of the window as shown in the screenshot below.\n\n\n\n\n\n\n\nClick New Item as shown below\n\n\n\n\n\n\n\nYou will be asked to select the project to which your export relates. If you do not see the correct project listed in the dropdown list, please reach out to our support team at support@coleridgeinitiative.org.\nAfter selecting a project, click Continue.\n\n\n\n\n\n\n\nRead through the entire page that loads. This page, titled “Create Export Request,” will ask for you to comment on all supporting code files to explain the commands used to generate the files in the export request. The Export Review team will reject all requests containing intermediate output, and there should be no more than 10 separate files for export unless approval is given in advance. The Export Review team will typically release export requests within five business days. However, if the team has any clarifying questions, this could result in a longer review process. You need to document your output files in the text box provided. See the example below:\n\n\n\n\n\n\n\nWhen you have read through and followed the page instructions, and are ready to proceed:\n\nMove the slider at the bottom of the page to indicate that you have followed the page’s guidelines.\nAt the bottom of the page, upload each of the files that you have prepared.\nClick Submit Request… to create the export request.\n\n\n\n\n\n\nYou can click My Requests at the left side of the window to view your current and previous export requests.\n\nTo learn more about exporting results, please watch these videos."
  },
  {
    "objectID": "packages.html#adding-additional-packages-in-rpython",
    "href": "packages.html#adding-additional-packages-in-rpython",
    "title": "8  Adding Additional Packages in R/Python",
    "section": "Adding Additional Packages in R/Python",
    "text": "Adding Additional Packages in R/Python\nIn order to request additional packages in R/Python, please email support@coleridgeinitiative.org with the following information:\n\nPackage name and configuration.\nA list of dependencies (whether the packages depend on OS-specific libraries (DLLs, .so)).\nA simple validation script to confirm the installation was successful. \n\nThe third item allows Coleridge to verify that the package is accessible from within your Python/R environment. The validation script below demonstrates importing a package (tensorflow) and running a functionality specific to that package (config.list_physical_devices()). If the install was unsuccessful, then the import or the function would fail to run."
  },
  {
    "objectID": "support.html#technical-support",
    "href": "support.html#technical-support",
    "title": "9  Support",
    "section": "Technical Support",
    "text": "Technical Support\nFor ADRF technical support, please email support@coleridgeinitiative.org"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Confidential Information Protection and Statistical Efficiency Act of 2002. (Washington, DC: U.S. GPO, 2002).\nFederal Committee on Statistical Methodology. \"Report on Statistical Disclosure Limitation Methodology,\" 22 (Second Version, 2005). https://nces.ed.gov/fcsm/pdf/spwp22.pdf.\n\"How to Use Microdata Properly: Self-Study Material for the Users of Eurostat Microdata Sets.\" (2018). https://ec.europa.eu/eurostat/web/microdata/overview/self-study-material-for-microdata-users.\nResearch Data Centre of the German Federal Employment Agency at the Institute for Employment Research. \"Remote Data Access and On-Site Use at the FDZ of the BA at the IAB.\" (2020, December 8). http://doku.iab.de/fdz/access/Vorgaben_DAFE_EN.PDF\nWelpton, Richard. Handbook on Statistical Disclosure Control for Outputs. (figshare, 2019). [https://doi.org/10.6084/m9.figshare.9958520.v1](https://doi.org/10.6084/m9.%22gshare.9958520.v1 “https://doi.org/10.6084/m9.”gshare.9958520.v1”)."
  }
]